{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a binary recommendation system with RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's the famous movie lens dataset you can read more about it [here](https://grouplens.org/datasets/movielens/).\n",
    "- Here I'm gonna use the 100k old version of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training dataset and convert it to numpy array\n",
    "training_set_df = pd.read_csv('dataset/u1.base', delimiter = '\\t')\n",
    "training_set = np.array(training_set_df, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        1,        16,         5, 878543541])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as shown above the first coulnm refers to the userID, the second one to movieId , the third to the movie rating and the last one refers to time that the user gives the movie the rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        1,        36,         2, 875073180])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the test dataset and convert it to numpy array\n",
    "test_set_df = pd.read_csv('dataset/u1.test', delimiter='\\t')\n",
    "test_set = np.array(test_set_df, dtype=int)\n",
    "test_set[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data will be a giant matrix each row of the matrix represent a user and its rating\n",
    "    > e.g: the first row represent the first user, and the first coulmn in the first row represent the rating from the first user to the first movie\n",
    "    \n",
    "    > e.g: matrix[5, 28] -> that will give us the rating from the user number \\#5 to the movie \\#28\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the max user_id, and the max movie_id\n",
    "    > two know what will be the dimensions of our matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we want to get total number of users and the same for movies movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the cell below, We are taking the maximum number from both the test set and the trainning set because the they are randomly suffeled for both the user and  the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users 943, The number of movies 1682\n"
     ]
    }
   ],
   "source": [
    "# printing the results\n",
    "print(f'The number of users {nb_users}, The number of movies {nb_movies}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- List of User 1: [Ratings of all the movies by User 1]\n",
    "- List of User 2: [Ratings of all the movies by User 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Define a function to use it to convert both of the training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the below function some points to explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what we are trying to do here is to make a list of lists and every list correspond to a specific user and every element in the list correspondse to the specific movie  \n",
    "\n",
    "- first we are creating an empty list\n",
    "- then loop in range of the number of users in our data and in every step we create a list of length of the number of movies and every value will represent a rate for that movie.\n",
    "- For every user that didn't rate a movie we will put a zero on that element\n",
    "- and for every rate we put it in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fn(data):\n",
    "    converted_data = []\n",
    "    \n",
    "    for user_id in range(1, nb_users + 1):\n",
    "        # getting all the movies ids that rated by every user\n",
    "        movies_for_user_id = data[:, 1][data[:, 0] == user_id] # getting the movies ids that taken be the current user in the for loop\n",
    "        rating_for_user_id = data[:, 2][data[:, 0] == user_id]\n",
    "        \n",
    "        ratings = np.zeros(nb_movies) # initialze all the ratings with zeros then include the rated movies\n",
    "        ratings[movies_for_user_id - 1] = rating_for_user_id\n",
    "        converted_data.append(list(ratings))\n",
    "        \n",
    "    return converted_data        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To chk if our function working let's print some data to get some intuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That is the rating value:3, for the movie numeber:2 from the user number:1\n",
      "That is the rating value:4, for the movie numeber:3 from the user number:1\n",
      "That is the rating value:3, for the movie numeber:4 from the user number:1\n"
     ]
    }
   ],
   "source": [
    "print(f'That is the rating value:{training_set[0, 2]}, for the movie numeber:{training_set[0, 1]} from the user number:{training_set[0, 0]}')\n",
    "print(f'That is the rating value:{training_set[1, 2]}, for the movie numeber:{training_set[1, 1]} from the user number:{training_set[1, 0]}')\n",
    "print(f'That is the rating value:{training_set[2, 2]}, for the movie numeber:{training_set[2, 1]} from the user number:{training_set[2, 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some intuations from the previous prints:\n",
    "- the user didn't rate movie \\#1 as the first row represent the movie \\#2\n",
    "    - So the first element in the first list should be 0\n",
    "- the begging of the first list should look like this \\[0, 3, 4, 3...\\]\n",
    "- so let's convert them and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training = convert_fn(training_set)\n",
    "new_test = convert_fn(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the first **list** from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 3.0, 4.0, 3.0, 3.0, 0.0, 4.0, 1.0, 5.0, 0.0]\n",
      "\n",
      "The dimensions of the data is 943 X 1682\n"
     ]
    }
   ],
   "source": [
    "print(new_training[0][:10]) #printing the first ten elemnts in the first list\n",
    "print(f'\\nThe dimensions of the data is {len(new_training)} X {len(new_training[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we expected the first four values are true and the dimensions are good\n",
    "- So we good to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data into torch tesnors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_d = torch.FloatTensor(new_training)\n",
    "test_d = torch.FloatTensor(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The last step in data preprocessing:\n",
    "- Is to convert all the rating into **Binary rating** `1` if it's a positive rating and `0` if it's negative and `-1` for movies that didn't get rated.\n",
    "- Positive movies have rate value from (3 to five).\n",
    "- negative movies have rate value (1 or 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training_set\n",
    "training_d[training_d == 0] = -1 # movies that didn't get rated\n",
    "training_d[training_d == 1] = 0 \n",
    "training_d[training_d == 2] = 0 \n",
    "training_d[training_d >= 3] = 1 \n",
    "\n",
    "# Test_set\n",
    "test_d[test_d == 0] = -1 # movies that didn't get rated\n",
    "test_d[test_d == 1] = 0 \n",
    "test_d[test_d == 2] = 0 \n",
    "test_d[test_d >= 3] = 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating Our RBM Architcture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First we are gonna creat the RBM class\n",
    "Inside this class we are goining to create 3 functions\n",
    "    - \\_\\_init\\_\\_ to initialize the weight and biases\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.bias_h = torch.randn(1, nh) # bias for the hidden nodes \n",
    "        self.bias_v = torch.randn(1, nv) # bias for the visible nodes \n",
    "        \n",
    "    def sample_h(self, x): # x -> The visible neurons in the probablities of p(h) given v\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.bias_h.expand_as(wx) # using expaned_as to make the dimensions consistent\n",
    "        p_hidden_given_visible = torch.sigmoid(activation)\n",
    "        \n",
    "        return p_hidden_given_visible, torch.bernoulli(p_hidden_given_visible)\n",
    "    \n",
    "    def sample_v(self, y): # x -> The visible neurons in the probablities of p(h) given v\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.bias_v.expand_as(wy) # using expaned_as to make the dimensions consistent\n",
    "        p_visible_given_hidden = torch.sigmoid(activation)\n",
    "        \n",
    "        return p_visible_given_hidden, torch.bernoulli(p_visible_given_hidden)\n",
    "    \n",
    "    # train what we are doing here is to update the weights and biases \n",
    "    # Using contrastive divergence \n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.bias_v += torch.sum((v0 - vk), 0)\n",
    "        self.bias_h += torch.sum((ph0 - phk), 0)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    }
   ],
   "source": [
    "nv = len(training_d[0]) \n",
    "print(len(training_d[0]) )\n",
    "nh = 100 # parameter to tune to try getting the best results\n",
    "batch_zs = 100\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.2498481571674347\n",
      "Epoch: 2, loss: 0.245169535279274\n",
      "Epoch: 3, loss: 0.24612638354301453\n",
      "Epoch: 4, loss: 0.24486500024795532\n",
      "Epoch: 5, loss: 0.2459617406129837\n",
      "Epoch: 6, loss: 0.24962538480758667\n",
      "Epoch: 7, loss: 0.2453438639640808\n",
      "Epoch: 8, loss: 0.24563489854335785\n",
      "Epoch: 9, loss: 0.2427835464477539\n",
      "Epoch: 10, loss: 0.24556803703308105\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 10\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    train_loss = 0\n",
    "    counter = 0.\n",
    "    \n",
    "    for id_usr in range(0, nb_users - batch_zs, batch_zs):\n",
    "        vk = training_d[id_usr:id_usr+batch_zs] # that is our input\n",
    "        v0 = training_d[id_usr:id_usr+batch_zs] # that is our target the same as the input but not updated\n",
    "        ph0, _ = rbm.sample_h(v0)\n",
    "        \n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0] # avoid updating the the non rated movies\n",
    "        \n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "        # then call the train function to update the weights and biases\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0])) # taking the difference between the target and the input\n",
    "        counter += 1.\n",
    "    print(f'Epoch: {epoch}, loss: {train_loss / counter}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.2568473815917969\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "counter = 0.\n",
    "\n",
    "for id_usr in range(nb_users):\n",
    "    v = training_d[id_usr:id_usr+1] # that is our input\n",
    "    vt = test_d[id_usr:id_usr+1] # that is our target the same as the input but not updated\n",
    "    \n",
    "    if len(vt[vt >= 0]) > 0:\n",
    "        _, h = rbm.sample_h(v)\n",
    "        _, v = rbm.sample_v(h)\n",
    "\n",
    "        test_loss += torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0])) # taking the difference between the target and the input\n",
    "        counter += 1.0\n",
    "print(f'test loss: {test_loss / counter}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get about 75% of success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hope you enjoyed it,  \n",
    "Thanks for reading.  \n",
    "Peace ^_^**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
